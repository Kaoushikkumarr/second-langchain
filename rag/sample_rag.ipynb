{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf42b362",
   "metadata": {},
   "source": [
    "## RAG Pipeline with Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98fe9e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"6.1+ years of industry experience in Python Scripting, Django, Flask,\\nFast-API, Postgres SQL, MongoDB, Elastic Search, MySQL, GCP,\\nRabbitMQ, Big Query, Pub-Sub, AlloyDB, Jira, Agile, Micro-Services &\\nMainframe Operations, Tools and Techniques- WebEnabler,\\nOperation Sentinel Console, MISER\\nPython Developer\\n66 Degrees Internation PVT. LTD.(Formally QWINIX\\nTECHNOLOGIES PVT. LTD), Mysuru\\nPLATFORM: Python, Fast-API, Flask, GCP, GIT, Docker,\\nMicro-Services.\\nThese technologies have been used for Cloud\\nNative and Product Modernization, which is\\nbeing designed to migrate the Legacy System\\nDatabase records to Google Cloud\\nPlatform(GCP) to solve the real time cloud\\nproblems for Large Industries.\\nPROJECT DESCRIPTIONS:\\nData Validation Tools(DVT) is an open-source\\nrepository provided by Google, which allows the\\nsmooth Migration of Legacy Databases across the\\nGoogle Cloud Platform Databases.\\nThis is micro-service has been developed to\\nreceived the various payload as Databases\\nconnection request which will be responsible for\\nmigrating legacy system DBs to Cloud DB.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\ncompanies to structuring there DB.\\nWorked on Fast-API, Flask, GCP, GitHub, Jira,\\nDocker, AlloyDB.\\n2023-03 -\\n2023-09\\nSenior Software Engineer\\nImpact Big Data Analytics Pvt. Ltd, Bangalore\\nPLATFORM: Python, Fast-API, PostgreSQL, GIT, Micro-\\n2022-04 -\\n2023-03\\nAddress\\nBangalore, Karnataka\\n560036\\nPhone\\n+91 8608121704\\nE-mail\\nKaoushikkumarr@gmail.co\\nm\\nhttps://www.linkedin.com\\n/in/kaoushik-kumar-\\n99426060/\\nPython\\nFast-API\\nFlask\\nDjango\\nCompetencies\\nServices.\\nThese technologies are used in most of AI Based\\nPlatform Application, which is being designed to\\nsolve real time e-commerce problems for Large\\nRetail Industries.\\nPROJECT DESCRIPTIONS:\\nMTP is one of the Micro-Service Based Platform\\nArchitect responsible for handling Multi-Tenant\\nApplication.\\nThis is one of Platform Service which is being built\\nfor handling all Multi-Tenant Based services\\naltogether.\\nPython is being used in backend to solve\\nchallenging problems of Large E-commerce\\ncompanies to increase their Revenues,\\nStructuring Ware-house products and many\\nmore.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nEmployD is one of the other Micro-Service Based\\napplication for Recruitment.\\nThis is another Platform Service which is being\\nbuilt for handling all Multi-Tenant Based services\\naltogether.\\nPython is being used in backend to solve\\nrecruitment problems of SMB or Small companies\\nto fulfill part-time or full-time employment for both\\nEmployee and Employers.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nPrice Smart is one of the another Micro-Service\\nBased application for E-commerce.\\nThis is one of application which is being designed\\nto optimism price of e-commerce products\\nbased on seasonal basis to enhance the sells for\\nmonths.\\nPython is being used in backend using Data\\nScience libraries.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nSoftware Development Engineer 1\\nEdGE Networks PVT. LTD.(C2H), Bangalore\\nPLATFORM: Python, Fast-API, Flask, PostgreSQL,\\nMongoDB, Elastic Search, GIT, Docker, RabbitMQ,\\n2020-07 -\\n2022-04\\nSQL\\nMySQL\\nGit\\nJIRA\\nMicrosoft Outlook\\nDocker\\nSQL Server\\nMongoDB\\nPostgreSQL\\nElastic Search\\nRabbit-MQ\\nPub-Sub\\nBig Query\\nAlloy DB\\nGCP\\nAgile\\nGitHub\\nOffice 365\\nHTTP\\nGoogle Docs\\nPostman\\nCloud Services\\nPython, Fast-API,\\nFlask, Django, PostgreSQL,\\nMongoDB, ElasOc Search,\\nGIT, Docker, RabbitMQ\\nMicro-Services, HTML, CSS,\\nBootstrap, Java Script,\\njQuery, Core Java.\\nGoogle Cloud\\nPlatform(GCP)\\nOS: Linux-Mint, Ubuntu,\\nWindows (10, 8.1, 8, 7,\\nServer), MacOS.\\nVersion Control: GitHub, Bit\\nBucket, GitLab.\\nDevOps: Docker.\\nTicketing Tools: Jira, CMS\\nHobbies\\nMicro-Services.\\nThese technologies are used in most of our AI\\nBased Application, which is being designed to\\nsolve the real time recruitment problems for Large\\nEnterprises Industries.\\nPROJECT DESCRIPTIONS:\\nIntegrations is one of the Micro-Service Based\\nArchitect Application responsible to communicate\\nwith various Third Parties Application.\\nThis is Inbound and Outbound Micro-Service\\nApplication which is responsible to communicate\\nwith various Third Party's Application by using their\\nservices into our Platform Based Application as\\nwell as to Another Products.\\nThe idea behind this service is to not to allow any\\nThird Party's API directly to use Platform Base\\nApplication as vice-versa.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\nduring the time of their Recruitments.\\nWorked on Fast-API, Flask, PostgreSQL, RabbitMQ,\\nGitLab, Docker, Jira.\\nPathfinder is one of the Career Progression\\nApplication based on AI platform.\\nThis is one of the Wrapper Based Application (also\\ncalled as BFF) which multi-Tenant (i.e: Clients)\\nbased product, can be communicated with\\nPlatform-Based-Application (i.e., TDP) to suggest\\nthe Next Career Progression Road Map to the\\nInternal Employees and helping them to choose\\nanother latest technology for their Career\\nGrowth.\\nPython is being used in backend by using Flask as\\nFramework to solve the challenges and problems\\nof Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nRecruit is one of the Recruitment Application based\\non AI platform\\nThis is another Wrapper Based Application (also\\ncalled as BFF) which multi-Tenant (i.e.; Clients)\\nbased product, can be communicated with\\nAgile\\nRESTFul\\nDatabase programming\\nProgramming\\nProduct development\\nTesting and maintenance\\nAPI design knowledge\\nWeb-based software\\nengineering\\nBuild releases\\nCode reviews\\nReading News Paper,\\nWatching News, Yoga.\\nPlatform-Based-Application (i.e., TDP) to help to\\nresolve the various challenges at the One of\\nRecruitment of the New Joinee.\\nPython Script is used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nTDP is one of the latest and the Platform Based on AI\\nPlatform Service\\nThis is one of the latest Platform Based Service\\nwhich is being built as a product that can be\\nresponsible for handling all the Multi-Tenant\\nBased Wrapper (BFFs) products altogether.\\nAll the above products (i.e.; Integrations,\\nPathfinder, Recruit, etc..) have to be under the\\ncontrol of this TDP Platform.\\nPython Script is used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nCSE is one of the Older Version of Recruitment\\nApplication\\nThis is one of the Oldest Application of EdGE\\nNetwork, which has all the features of our Newest\\nApplication such as Integration as well as Recruit.\\nThe main difference is from the newest one is, it\\nhas no AI well as Tenant Based features.\\nPython has been used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, MongoDB, Elastic Search,\\nGitLab, Docker, Jira.\\nAssociate Product Engineer\\nTechtree IT Systems Pvt. Ltd, Bangalore\\nPLATFORM: Python, Django, MySQL, HTML, CSS,\\nBootstrap, Java Script, jQuery.\\nGIT, Pandas, Numpy, Excel.\\nThe Reciproci is a platform to create, store,\\nupdate, and \\uf001x the Ecommerce, Loyalty market\\ndeals.\\nThe Reciproci is Market Software developed on\\nnative windows platform.\\nWorked with Data Science team using latest tools\\n2020-02 -\\n2020-04\\nand techniques in trend.\\nPROJECT DESCRIPTION:\\nClub Apparel is one of the applications for\\nEcommerce.\\nEnd-to-End Build and Release Engineering and\\nConfiguration Management processes.\\nPython Script is used for backend to generate a\\nSales Reports on daily basic.\\nWorked on GIT, Bit Bucket, Jira.\\nHouse of Beauty is one of the applications for\\nEcommerce.\\nEnd-to-End Build and Release Engineering and\\nConfiguration Management processes.\\nPython Script is used for backend to generate a\\nSales Reports on daily basic.\\nWorked on GIT, Bit Bucket, Jira.\\nSystem Engineer\\nFidelity Information Services India PVT. LTD.(C2H),\\nBangalore\\nPLATFORM: Python, Django, Web Enabler, Operation\\nSentinel Console, MISER BI, Bastion Server, HTML,\\nCSS, Bootstraps, JavaScript, jQuery, PostgresDB,\\nPandas, Numpy, CORE JAVA.\\nPROJECT DESCRIPTION:\\nFinancial Claim Application which is used directly\\nto track the remarks/comments and process the\\ncustomers claim accordingly by releasing the\\nfund to participate at instances.\\nStock Market Web Application platform to\\nengage multiple users to check market rate and\\nbring investors to invest on various company's\\nportfolios.\\nImage Processing Application which is used to\\ndetect the facial images to unlock the\\napplication.\\nWeb Application for Real Estate which brings the\\nplatform for Realtors who can create, store,\\nupdate, sell, purchase or advertise their Real\\nEstate properties\\nWeb Application to manage the User profile,\\nBlogs and Comment\\n2017-08 -\\n2020-02\\nEducation\\nGUI Application through which Banking Dataset\\n& Transaction queries can be managed\\nWeb Navigation System to \\uf001nd the Bank's\\nLocation, Branch Locations, ATM Locations and\\ncan implements more locations such as Best\\nHotels, Restaurants and Tour Places of country\\nWeb Insurance Application to search the closest\\nCustomer Details and their Policy Information\\nWeb Application to \\uf001nd out the closest account\\ndetails and statements of Users\\nWeb Enabler is a tool of Unisys Mainframe use for\\nupdating, cancellations of the Bank\\nCurrent.Transactions, Transactions History while\\ncreating the .Ach File, also use for checking the\\nATM Transactions, issues and \\uf001x it\\nOperation Sentinel Console is one of another\\ntools of Unisys Mainframe which is used to\\nmonitor, control the alerts during the Transaction\\nperiods\\nMISER Business Intelligence is the monitoring\\napplication of FIS use to confirm the Bank\\nTransactions, ATM Transactions, Predecessors and\\nFollowers Transactions End to End.\\nBACHELOR OF ENGINEERING: Computer\\nScience And Engineering\\nANNAMALAI UNIVERSITY - Chidambaram, Tamil\\nNadu\\nGPA: 6.88, Good academic background and\\nrecognitions. Participated in various team playing\\nactivities as Student Welfare Member, Volunteered\\nvarious events. Took part in various social activities\\nsuch as YRC Blood Donation Camp, NSS Services,\\nand General Election Volunteer. A proud\\nrepresentative for Hostels In-mates welfare for\\nconsecutive two years.\\n2012-08 -\\n2016-05\\nHSC: Intermediate of Science\\nLALOO MANDAL HIGH SCHOOL - Gaya, Bihar\\nGPA: 65%, Good Academic Knowledge.\\nParticipated in various Extra Curricular Activities. Part\\nof the School Cricket team.\\n2010-03 -\\n2012-03\\nNo Degree: All Subjects\\nSHIVAM PUBLIC SCHOOL - Patna, Bihar\\nPercentage: 68%.\\n2008-04 -\\n2009-02\", metadata={'source': '../cc.txt'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Ingestion\n",
    "# This script is used to ingest data from a source and process it for further analysis.\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"../cc.txt\", encoding=\"utf-8\")\n",
    "text_doc = loader.load()\n",
    "text_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9333c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9906cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n\\n\\nContents\\n\\nIntroduction\\nPrerequisites\\nGet the JSON data “actions” object ready\\nTwo key benefits of helpers of bulk API’s\\nJSON file bulk document indexing – use a custom generator\\nConclusion\\nPython helpers bulk load elasticsearch: The entire code\\n\\n\\n\\n\\n\\n\\n\\nResourcesElasticsearchHow to use Python helpers to bulk load data into an Elasticsearch index\\n\\n\\nHow to use Python helpers to bulk load data into an Elasticsearch index\\n\\n\\n\\n\\nWritten by Data Pilot\\nApril 09, 2019\\n\\n\\n\\n\\nElasticsearch\\nPython\\n\\n\\n\\n\\n\\n Subscribe\\n\\t\\t\\n\\n\\n\\n Like\\n\\t\\t\\n\\n \\n\\n\\n\\nHave a Database Problem?  Speak with an Expert for Free\\n\\t\\t\\n Get Started >>\\n\\n\\n\\n\\nIntroduction\\nPython helpers do exactly what they say: They help you get things done. One of the most efficient ways to streamline indexing is through the helpers.bulk method. Indexing large datasets without putting them into memory is the key to expediting search results and saving system resources. Learn exactly how to call the bulk method with this step-by-step tutorial about Python  helpers bulk load Elasticsearch. \\nThe structure of the helpers.bulk method: \\n1helpers.bulk( {CLIENT_OBJ}, {ACTION_ITERATOR}, {INDEX_NAME}, {DOC_TYPE} )\\n\\nThe client instance helpers.bulk( {CLIENT_OBJ} is the first parameter you see in the code\\n\\nThe custom iterator {ACTION_ITERATOR} gives the iteration for document bulk indexing of several documents \\n\\nIf in the action iterator, the index name, and it’s document type are not declared, they can be passed along as strings \\n\\nRead Elasticsearch documentation for the complete helpers class parameter list\\n\\n\\nTip: For API calls, Elasticsearch uses slightly different parameters in two situations to avoid conflicts with Python’s keyword list. It uses doc_type and from_ in place of type and from. The API list contains more details. \\n\\nPrerequisites\\n\\nPython – Install the latest version for your platform such as MacOS, Windows, Unix and Unix-like (Linux), and more. \\n\\nPython client library (low-level) for Elasticsearch – Install Python 3 because Python 2 will soon be outdated. It expires when the year 2020 arrives. Use the python command for Pyton2.x if you want to use Python 2 until it becomes unavailable. Otherwise, for Python 3.x use python3.\\n\\nThe correct client module must be installed or you’ll see the error message ImportError: No module named Elasticsearch or a similar one. \\n\\nInstall the client library with pip.\\n\\n12pip install elasticsearch # Python 2 install \\npip3 install elasticsearch # Python 3 install\\n\\nRun Elasticsearch. Use the GET request for cURL.\\n\\n12curl -XGET http://localhost:9200/ \\n# or try.. curl -XGET https://{YOUR_DOMAIN}:{YOUR_CUSTOM_PORT}\\n\\nTo confirm that Elasticsearch is running, use the requests library from Python.\\n\\n123import requests \\nres = requests.get(\\'http://localhost:9200\\') \\nprint(res.content)\\n\\nDocuments will be bulked into an Elasticsearch index. Bring up the index list of those documents with the following cURL request. \\n\\n1curl -XGET localhost:9200/_cat/indices?v\\n\\nThis example shows the document’s ID as a custom universally unique identifier (UUID). You can do the same thing if you import these three:\\n\\nPython’s UUID module – Supports Python 2.3 or higher.\\n\\nThe helper’s module – Python helpers to import Elasticsearch data. The module supports these platforms: Python 2.6+ and Python 3.2+ on Windows in process, Python 3.2+ on Unix Portable Operating System Interface (POSIX). Read the helper documentation to find out additional details about the API’s function.\\n\\nAn operating system – The OS interface you have or prefer to use, for example, Windows, MacOS, or Linux/Unix.\\n\\nHere’s an example of the header script: \\n\\n\\n1234#!/usr/bin/env python3 \\n#-*- coding: utf-8 -*- \\nfrom elasticsearch import Elasticsearch, helpers \\nimport os, uuid\\nGet the JSON data “actions” object ready\\n\\nThe list object that behaves like an iterator is helpers.bulkand the actions paramenter gets passed there. \\n\\nSee the example below. Using the for loop method, 100 various documents are created. \\n\\n\\n12345678910111213141516171819202122actions = [\\n\\xa0 \\xa0 {\\n\\xa0 \\xa0 \\xa0 \\xa0 \"_id\" : uuid.uuid4(), # random UUID for _id\\n\\xa0 \\xa0 \\xa0 \\xa0 \"doc_type\" : \"person\", # document _type\\n\\xa0 \\xa0 \\xa0 \\xa0 \"doc\": { # the body of the document\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"name\": \"George Peterson\",\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"sex\": \"male\",\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"age\": 34+doc,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"years\": 10+doc\\n\\xa0 \\xa0 \\xa0 \\xa0 }\\n\\xa0 \\xa0 }\\n\\xa0 \\xa0 for doc in range(100)\\n]\\n\\ntry:\\n\\xa0 \\xa0 # make the bulk call, and get a response\\n\\xa0 \\xa0 response = helpers.bulk(elastic, bulk_json_data(\"people.json\", \"employees\", \"people\"))\\n\\n\\xa0 \\xa0 #response = helpers.bulk(elastic, actions, index=\\'employees\\', doc_type=\\'people\\')\\n\\xa0 \\xa0 print (\"\\\\nRESPONSE:\", response)\\nexcept Exception as e:\\n\\xa0 \\xa0 print(\"\\\\nERROR:\", e)\\nTwo key benefits of helpers of bulk API’s\\nThe beauty of the bulk helpers is that by design, they accept two things:\\n\\nAn iterable which can double as a generator so you can bypass loading huge datasets into memory and still index them fast. \\n\\nAn Elasticsearch class is also what every bulk helper accepts.\\n\\n\\nJSON file bulk document indexing – use a custom generator\\nHere’s an example of a JSON file containing several Elasticsearch documents:\\n123456789101112{\"index\":{}} \\n{\"name\": \"Moghul Hecuba\", \"age\": \"48\", \"sex\": \"female\", \"accounts\": \"moghul_hecuba\", \"join_date\": \"2011-07-25\"} \\n{\"index\":{}} \\n{\"name\": \"Suffolk McGrath\", \"age\": \"36\", \"sex\": \"male\", \"accounts\": \"suffolk_mcgrath\", \"join_date\": \"2015-04-21\"} \\n{\"index\":{}} \\n{\"name\": \"McMullen Benzedrine\", \"age\": \"41\", \"sex\": \"male\", \"accounts\": \"mcmullen_benzedrine\", \"join_date\": \"2012-01-05\"} \\n{\"index\":{}} \\n{\"name\": \"Angus Harley\", \"age\": \"55\", \"sex\": \"male\", \"accounts\": \"angus_harley\", \"join_date\": \"2014-01-31\"} \\n{\"index\":{}} \\n{\"name\": \"Darlene Corinth\", \"age\": \"43\", \"sex\": \"male\", \"accounts\": \"darlene_corinth\", \"join_date\": \"2015-06-02\"} \\n[...] \\n[...]\\nEach document has it’s own respective row, and a header row indicating the Elasticsearch index. These example documents don’t specify the Elasticsearch index name, because the index will be passed to the helpers.bulk() method’s API call later on.\\nNow, get the working path for the Python script by creating a function if the JSON file and the script are in the same directory:\\n1234567891011\\'\\'\\'\\na simple function that gets the working path of\\nthe Python script and returns it\\n\\'\\'\\'\\ndef script_path():\\n\\xa0 \\xa0 path = os.path.dirname(os.path.realpath(__file__))\\n\\xa0 \\xa0 if os.name == \\'posix\\': # posix is for macOS or Linux\\n\\xa0 \\xa0 \\xa0 \\xa0 path = path + \"/\"\\n\\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 path = path + chr(92) # backslash is for Windows\\n\\xa0 \\xa0 return path\\n\\nIf the JSON file and Python script are in different directories, use the example below. A custom path for the file name is available too. \\n\\n123456789def get_data_from_file(file_name):\\n\\xa0 \\xa0 if \"/\" in file_name or chr(92) in file_name:\\n\\xa0 \\xa0 \\xa0 \\xa0 file = open(file_name, encoding=\"utf8\", errors=\\'ignore\\')\\n\\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 # use the script_path() function to get path if none is passed\\n\\xa0 \\xa0 \\xa0 \\xa0 file = open(script_path() + str(file_name), encoding=\"utf8\", errors=\\'ignore\\')\\n\\xa0 \\xa0 data = [line.strip() for line in file]\\n\\xa0 \\xa0 file.close()\\n\\xa0 \\xa0 return data\\n\\nIterators, including functions for the action parameter are allowable with the Bulk API. Again, as you can see, generators enable large datasets won’t have to be loaded into memory to slow down the process. It’s the best way for Python helpers to import Elasticsearch data. \\n\\n1234567891011121314151617\\'\\'\\' \\ngenerator to push bulk data from a JSON \\nfile into an Elasticsearch index \\n\\'\\'\\' \\ndef bulk_json_data(json_file, _index, doc_type): \\n\\xa0 \\xa0 json_list = get_data_from_file(json_file)\\n\\xa0 \\xa0 for doc in json_list:\\n\\xa0 \\xa0 \\xa0 \\xa0 # use a `yield` generator so that the data\\n\\xa0 \\xa0 \\xa0 \\xa0 # isn\\'t loaded into memory\\n\\n\\xa0 \\xa0 \\xa0 \\xa0 if \\'{\"index\"\\' not in doc:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 yield {\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_index\": _index,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_type\": doc_type,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_id\": uuid.uuid4(),\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_source\": doc\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 }\\n>A Tip: To create a custom generator fast for the bulk load data helper Python technique, use the bulk method and the parameters in the example here below. \\n12345678helpers.bulk(\\n\\xa0 \\xa0 {CLIENT_INSTANCE},\\n\\xa0 \\xa0 bulk_json_data(\\n\\xa0 \\xa0 \\xa0 \\xa0 {JSON_FILE_NAME},\\n\\xa0 \\xa0 \\xa0 \\xa0 {INDEX_NAME},\\n\\xa0 \\xa0 \\xa0 \\xa0 {DOC_TYPE}\\n\\xa0 \\xa0 ) \\n)\\n\\nTry the bulk call the helpers.bulk method. Pass the whole bulk_json_data() as the actions parameter.\\n\\n123456try:\\n\\xa0 \\xa0 # make the bulk call, and get a response\\n\\xa0 \\xa0 response = helpers.bulk(elastic, bulk_json_data(\"people.json\", \"employees\", \"people\"))\\n\\xa0 \\xa0 print (\"\\\\nRESPONSE:\", response)\\nexcept Exception as e:\\n\\xa0 \\xa0 print(\"\\\\nERROR:\", e)\\nConclusion\\nin this tutorial, you learned how to use the helpers.bulk method. It is an excellent way to index large datasets without putting them into memory. This speeds up the indexing when you need to bulk import Elasticsearch data in Python. You save time by sreamlining processes to complete coding done faster with Python  helpers bulk load Elasticsearch.\\nAn example of a successful API call terminal output you might see looks like this. \\n1RESPONSE: (1000, [])\\nAlthough the above number in the output example shows “1000” documents, that number is fictitious. The actual document number you’ll see will reflect what’s contained in the JSON file. \\nPython  helpers bulk load elasticsearch: The entire code\\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#!/usr/bin/env python3 \\n#-*- coding: utf-8 -*- \\nfrom elasticsearch import Elasticsearch, helpers \\nimport os, uuid \\n\\n# create a new instance of the Elasticsearch client class \\nelastic = Elasticsearch() \\n# ...or uncomment to use this instead: \\n#elastic = Elasticsearch(\"localhost\") \\n\\n\\'\\'\\'\\na simple function that gets the working path of\\nthe Python script and returns it\\n\\'\\'\\'\\ndef script_path():\\n\\xa0 \\xa0 path = os.path.dirname(os.path.realpath(__file__))\\n\\xa0 \\xa0 if os.name == \\'posix\\': # posix is for macOS or Linux\\n\\xa0 \\xa0 \\xa0 \\xa0 path = path + \"/\"\\n\\xa0 \\xa0 else:\\n\\xa0 \\xa0 \\xa0 \\xa0 path = path + chr(92) # backslash is for Windows\\n\\xa0 \\xa0 return path\\n\\n\\n\\'\\'\\'\\nthis function opens a file and returns its\\ncontents as a list of strings split by linebreaks\\n\\'\\'\\'\\ndef get_data_from_file(self, path=script_path()):\\n\\xa0 \\xa0 file = open(path + str(self), encoding=\"utf8\", errors=\\'ignore\\')\\n\\xa0 \\xa0 data = [line.strip() for line in file]\\n\\xa0 \\xa0 file.close()\\n\\xa0 \\xa0 return data\\n\\n\\'\\'\\'\\ngenerator to push bulk data from a JSON\\nfile into an Elasticsearch index\\n\\'\\'\\'\\ndef bulk_json_data(json_file, _index, doc_type):\\n\\xa0 \\xa0 json_list = get_data_from_file(json_file)\\n\\xa0 \\xa0 for doc in json_list:\\n\\xa0 \\xa0 # use a `yield` generator so that the data\\n\\xa0 \\xa0 # isn\\'t loaded into memory\\n\\xa0 \\xa0 \\xa0 \\xa0 if \\'{\"index\"\\' not in doc:\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 yield {\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_index\": _index,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_type\": doc_type,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_id\": uuid.uuid4(),\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"_source\": doc\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 }\\n\\ntry:\\n\\xa0 \\xa0 # make the bulk call, and get a response\\n\\xa0 \\xa0 response = helpers.bulk(elastic, bulk_json_data(\"people.json\", \"employees\", \"people\"))\\n\\xa0 \\xa0 print (\"\\\\nbulk_json_data() RESPONSE:\", response)\\nexcept Exception as e:\\n\\xa0 \\xa0 print(\"\\\\nERROR:\", e)\\n\\n# iterator for a single document\\nactions = [\\n\\xa0 \\xa0 {\\n\\xa0 \\xa0 \\xa0 \\xa0 \"_id\" : uuid.uuid4(), # random UUID for _id\\n\\xa0 \\xa0 \\xa0 \\xa0 \"doc_type\" : \"person\", # document _type\\n\\xa0 \\xa0 \\xa0 \\xa0 \"doc\": { # the body of the document\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"name\": \"George Peterson\",\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"sex\": \"male\",\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"age\": 34,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"years\": 10\\n\\xa0 \\xa0 \\xa0 \\xa0 }\\n\\xa0 \\xa0 }\\n]\\n\\n# iterator for multiple docs\\nactions = [\\n\\xa0 \\xa0 {\\n\\xa0 \\xa0 \\xa0 \\xa0 \"_id\" : uuid.uuid4(), # random UUID for _id\\n\\xa0 \\xa0 \\xa0 \\xa0 \"doc_type\" : \"person\", # document _type\\n\\xa0 \\xa0 \\xa0 \\xa0 \"doc\": { # the body of the document\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"name\": \"George Peterson\",\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"sex\": \"male\",\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"age\": 34+doc,\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \"years\": 10+doc\\n\\xa0 \\xa0 \\xa0 \\xa0 }\\n\\xa0 \\xa0 }\\n\\xa0 \\xa0 for doc in range(100) # use \\'for\\' loop to insert 100 documents\\n]\\n\\ntry:\\n\\xa0 \\xa0 # make the bulk call using \\'actions\\' and get a response\\n\\xa0 \\xa0 response = helpers.bulk(elastic, actions, index=\\'employees\\', doc_type=\\'people\\')\\n\\xa0 \\xa0 print (\"\\\\nactions RESPONSE:\", response)\\nexcept Exception as e:\\n\\xa0 \\xa0 print(\"\\\\nERROR:\", e)\\n\\n\\n\\n\\nRate \\nGive Feedback\\n \\n\\n\\n\\nPilot the ObjectRocket Platform Free!\\n\\n\\nTry Fully-Managed CockroachDB, Elasticsearch, MongoDB, PostgreSQL (Beta) or Redis.\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Topics:\\n\\n\\nUse Elasticsearch to Index a Document in Windows\\n\\n\\nThe Elasticsearch List Indexes Tutorial\\n\\n\\nElasticsearch Dockerfile Example\\n\\n\\nElasticsearch and Scroll in Python\\n\\n\\n\\n\\nAdditional Information:\\n\\n\\nBuild an Elasticsearch Web Application in Python (Part 2)\\n\\n\\nBuild an Elasticsearch Web Application in Python (Part 1)\\n\\n\\nGet the mapping of an Elasticsearch index in Python\\n\\n\\nIndex a Bytes String into Elasticsearch with Python\\n\\n\\n\\n\\n\\n ', metadata={'source': 'https://kb.objectrocket.com/elasticsearch/how-to-use-python-helpers-to-bulk-load-data-into-an-elasticsearch-index'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Web Based Loader\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://kb.objectrocket.com/elasticsearch/how-to-use-python-helpers-to-bulk-load-data-into-an-elasticsearch-index\",\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "        class_=(\"wrap\", \"content\", \"sidebar\", \"table-of-contents\")\n",
    "    ))\n",
    ")\n",
    "web_doc = loader.load()\n",
    "web_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f05d9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Python Developer\\nWork History\\nContact\\nWWW\\nhttps://bold.pro\\n/my/kaoushik-kumar-\\n230928234654/465\\nLinkedIn\\nTechnical Profile\\nKaoushikKumar\\n6.1+ years of industry experience in Python Scripting, Django, Flask,\\nFast-API, Postgres SQL, MongoDB, Elastic Search, MySQL, GCP,\\nRabbitMQ, Big Query, Pub-Sub, AlloyDB, Jira, Agile, Micro-Services &\\nMainframe Operations, Tools and Techniques- WebEnabler,\\nOperation Sentinel Console, MISER\\nPython Developer\\n66 Degrees Internation PVT. LTD.(Formally QWINIX\\nTECHNOLOGIES PVT. LTD), Mysuru\\nPLATFORM: Python,Fast-API,Flask, GCP, GIT, Docker,\\nMicro-Services.\\nThese technologies have been used for Cloud\\nNative and Product Modernization, which is\\nbeing designed to migrate the Legacy System\\nDatabase records to Google Cloud\\nPlatform(GCP) to solve the real time cloud\\nproblems for Large Industries.\\nPROJECT DESCRIPTIONS:\\nData Validation Tools(DVT) is an open-source\\nrepository provided by Google, which allows the\\nsmooth Migration of Legacy Databases across the\\nGoogle Cloud Platform Databases.\\nThis is micro-service has been developed to\\nreceived the various payload as Databases\\nconnection request which will be responsible for\\nmigrating legacy system DBs to Cloud DB.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\ncompanies to structuring there DB.\\nWorked on Fast-API, Flask, GCP, GitHub, Jira,\\nDocker, AlloyDB.\\n2023-03 -\\n2023-09\\nSenior Software Engineer\\nImpact Big Data Analytics Pvt. Ltd, Bangalore\\nPLATFORM: Python, Fast-API, PostgreSQL, GIT, Micro-\\n2022-04 -\\n2023-03\\nAddress\\nBangalore, Karnataka\\n560036\\nPhone\\n+91 8608121704\\nE-mail\\nKaoushikkumarr@gmail.co\\nm\\nhttps://www.linkedin.com\\n/in/kaoushik-kumar-\\n99426060/\\nPython\\nFast-API\\nFlask\\nDjango', metadata={'source': '../bb.pdf', 'page': 0}),\n",
       " Document(page_content='Competencies\\nServices.\\nThese technologies are used in most of AI Based\\nPlatform Application, which is being designed to\\nsolve real time e-commerce problems for Large\\nRetail Industries.\\nPROJECT DESCRIPTIONS:\\nMTP is one of the Micro-Service Based Platform\\nArchitect responsible for handling Multi-Tenant\\nApplication.\\nThis is one of Platform Service which is being built\\nfor handling all Multi-Tenant Based services\\naltogether.\\nPython is being used in backend to solve\\nchallenging problems of Large E-commerce\\ncompanies to increase their Revenues,\\nStructuring Ware-house products and many\\nmore.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nEmployD is one of the other Micro-Service Based\\napplication for Recruitment.\\nThis is another Platform Service which is being\\nbuilt for handling all Multi-Tenant Based services\\naltogether.\\nPython is being used in backend to solve\\nrecruitment problems of SMB or Small companies\\nto fulfill part-time or full-time employment for both\\nEmployee and Employers.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nPrice Smart is one of the another Micro-Service\\nBased application for E-commerce.\\nThis is one of application which is being designed\\nto optimism price of e-commerce products\\nbased on seasonal basis to enhance the sells for\\nmonths.\\nPython is being used in backend using Data\\nScience libraries.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nSoftware Development Engineer 1\\nEdGE Networks PVT. LTD.(C2H), Bangalore\\nPLATFORM: Python, Fast-API, Flask, PostgreSQL,\\nMongoDB, Elastic Search, GIT, Docker, RabbitMQ,\\n2020-07 -\\n2022-04\\nSQL\\nMySQL\\nGit\\nJIRA\\nMicrosoft Outlook\\nDocker\\nSQL Server\\nMongoDB\\nPostgreSQL\\nElastic Search\\nRabbit-MQ\\nPub-Sub\\nBig Query\\nAlloy DB\\nGCP\\nAgile\\nGitHub\\nOffice 365\\nHTTP\\nGoogle Docs\\nPostman\\nCloud Services\\nPython, Fast-API,\\nFlask, Django, PostgreSQL,\\nMongoDB, ElasOc Search,\\nGIT, Docker, RabbitMQ\\nMicro-Services, HTML, CSS,\\nBootstrap, Java Script,\\njQuery, Core Java.\\nGoogle Cloud\\nPlatform(GCP)\\nOS: Linux-Mint, Ubuntu,\\nWindows (10, 8.1, 8, 7,\\nServer), MacOS.\\nVersion Control: GitHub, Bit\\nBucket, GitLab.\\nDevOps: Docker.\\nTicketing Tools: Jira, CMS', metadata={'source': '../bb.pdf', 'page': 1}),\n",
       " Document(page_content=\"Hobbies\\nMicro-Services.\\nThese technologies are used in most of our AI\\nBased Application, which is being designed to\\nsolve the real time recruitment problems for Large\\nEnterprises Industries.\\nPROJECT DESCRIPTIONS:\\nIntegrations is one of the Micro-Service Based\\nArchitect Application responsible to communicate\\nwith various Third Parties Application.\\nThis is Inbound and Outbound Micro-Service\\nApplication which is responsible to communicate\\nwith various Third Party's Application by using their\\nservices into our Platform Based Application as\\nwell as to Another Products.\\nThe idea behind this service is to not to allow any\\nThird Party's API directly to use Platform Base\\nApplication as vice-versa.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\nduring the time of their Recruitments.\\nWorked on Fast-API, Flask, PostgreSQL, RabbitMQ,\\nGitLab, Docker, Jira.\\nPathfinder is one of the Career Progression\\nApplication based on AI platform.\\nThis is one of the Wrapper Based Application (also\\ncalled as BFF) which multi-Tenant (i.e: Clients)\\nbased product, can be communicated with\\nPlatform-Based-Application (i.e., TDP) to suggest\\nthe Next Career Progression Road Map to the\\nInternal Employees and helping them to choose\\nanother latest technology for their Career\\nGrowth.\\nPython is being used in backend by using Flask as\\nFramework to solve the challenges and problems\\nof Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nRecruit is one of the Recruitment Application based\\non AI platform\\nThis is another Wrapper Based Application (also\\ncalled as BFF) which multi-Tenant (i.e.; Clients)\\nbased product, can be communicated with\\nAgile\\nRESTFul\\nDatabase programming\\nProgramming\\nProduct development\\nTesting and maintenance\\nAPI design knowledge\\nWeb-based software\\nengineering\\nBuild releases\\nCode reviews\\nReading News Paper,\\nWatching News, Yoga.\", metadata={'source': '../bb.pdf', 'page': 2}),\n",
       " Document(page_content='Platform-Based-Application (i.e., TDP) to help to\\nresolve the various challenges at the One of\\nRecruitment of the New Joinee.\\nPython Script is used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nTDP is one of the latest and the Platform Based on AI\\nPlatform Service\\nThis is one of the latest Platform Based Service\\nwhich is being built as a product that can be\\nresponsible for handling all the Multi-Tenant\\nBased Wrapper (BFFs) products altogether.\\nAll the above products (i.e.; Integrations,\\nPathfinder, Recruit, etc..) have to be under the\\ncontrol of this TDP Platform.\\nPython Script is used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nCSE is one of the Older Version of Recruitment\\nApplication\\nThis is one of the Oldest Application of EdGE\\nNetwork, which has all the features of our Newest\\nApplication such as Integration as well as Recruit.\\nThe main difference is from the newest one is, it\\nhas no AI well as Tenant Based features.\\nPython has been used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, MongoDB, Elastic Search,\\nGitLab, Docker, Jira.\\nAssociate Product Engineer\\nTechtree IT Systems Pvt. Ltd, Bangalore\\nPLATFORM: Python, Django, MySQL, HTML, CSS,\\nBootstrap, Java Script, jQuery.\\nGIT, Pandas, Numpy, Excel.\\nThe Reciproci is a platform to create, store,\\nupdate, and \\uf001x the Ecommerce, Loyalty market\\ndeals.\\nThe Reciproci is Market Software developed on\\nnative windows platform.\\nWorked with Data Science team using latest tools\\n2020-02 -\\n2020-04', metadata={'source': '../bb.pdf', 'page': 3}),\n",
       " Document(page_content=\"and techniques in trend.\\nPROJECT DESCRIPTION:\\nClub Apparel is one of the applications for\\nEcommerce.\\nEnd-to-End Build and Release Engineering and\\nConfiguration Management processes.\\nPython Script is used for backend to generate a\\nSales Reports on daily basic.\\nWorked on GIT, Bit Bucket, Jira.\\nHouse of Beauty is one of the applications for\\nEcommerce.\\nEnd-to-End Build and Release Engineering and\\nConfiguration Management processes.\\nPython Script is used for backend to generate a\\nSales Reports on daily basic.\\nWorked on GIT, Bit Bucket, Jira.\\nSystem Engineer\\nFidelity Information Services India PVT. LTD.(C2H),\\nBangalore\\nPLATFORM: Python, Django, Web Enabler, Operation\\nSentinel Console, MISER BI, Bastion Server, HTML,\\nCSS, Bootstraps, JavaScript, jQuery, PostgresDB,\\nPandas, Numpy, CORE JAVA.\\nPROJECT DESCRIPTION:\\nFinancial Claim Application which is used directly\\nto track the remarks/comments and process the\\ncustomers claim accordingly by releasing the\\nfund to participate at instances.\\nStock Market Web Application platform to\\nengage multiple users to check market rate and\\nbring investors to invest on various company's\\nportfolios.\\nImage Processing Application which is used to\\ndetect the facial images to unlock the\\napplication.\\nWeb Application for Real Estate which brings the\\nplatform for Realtors who can create, store,\\nupdate, sell, purchase or advertise their Real\\nEstate properties\\nWeb Application to manage the User profile,\\nBlogs and Comment\\n2017-08 -\\n2020-02\", metadata={'source': '../bb.pdf', 'page': 4}),\n",
       " Document(page_content=\"Education\\nGUI Application through which Banking Dataset\\n& Transaction queries can be managed\\nWeb Navigation System to \\uf001nd the Bank's\\nLocation, Branch Locations, ATM Locations and\\ncan implements more locations such as Best\\nHotels, Restaurants and Tour Places of country\\nWeb Insurance Application to search the closest\\nCustomer Details and their Policy Information\\nWeb Application to \\uf001nd out the closest account\\ndetails and statements of Users\\nWeb Enabler is a tool of Unisys Mainframe use for\\nupdating, cancellations of the Bank\\nCurrent.Transactions, Transactions History while\\ncreating the .Ach File, also use for checking the\\nATM Transactions, issues and \\uf001x it\\nOperation Sentinel Console is one of another\\ntools of Unisys Mainframe which is used to\\nmonitor, control the alerts during the Transaction\\nperiods\\nMISER Business Intelligence is the monitoring\\napplication of FIS use to confirm the Bank\\nTransactions, ATM Transactions, Predecessors and\\nFollowers Transactions End to End.\\nBACHELOR OF ENGINEERING: Computer\\nScience And Engineering\\nANNAMALAI UNIVERSITY - Chidambaram, Tamil\\nNadu\\nGPA: 6.88, Good academic background and\\nrecognitions. Participated in various team playing\\nactivities as Student Welfare Member, Volunteered\\nvarious events. Took part in various social activities\\nsuch as YRC Blood Donation Camp, NSS Services,\\nand General Election Volunteer. A proud\\nrepresentative for Hostels In-mates welfare for\\nconsecutive two years.\\n2012-08 -\\n2016-05\\nHSC: Intermediate of Science\\nLALOO MANDAL HIGH SCHOOL - Gaya, Bihar\\nGPA: 65%, Good Academic Knowledge.\\nParticipated in various Extra Curricular Activities. Part\\nof the School Cricket team.\\n2010-03 -\\n2012-03\", metadata={'source': '../bb.pdf', 'page': 5}),\n",
       " Document(page_content='No Degree: All Subjects\\nSHIVAM PUBLIC SCHOOL - Patna, Bihar\\nPercentage: 68%.\\n2008-04 -\\n2009-02', metadata={'source': '../bb.pdf', 'page': 6})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PDF Reader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"../bb.pdf\")\n",
    "pdf_doc = loader.load()\n",
    "pdf_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16064f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Python Developer\\nWork History\\nContact\\nWWW\\nhttps://bold.pro\\n/my/kaoushik-kumar-\\n230928234654/465\\nLinkedIn\\nTechnical Profile\\nKaoushikKumar\\n6.1+ years of industry experience in Python Scripting, Django, Flask,\\nFast-API, Postgres SQL, MongoDB, Elastic Search, MySQL, GCP,\\nRabbitMQ, Big Query, Pub-Sub, AlloyDB, Jira, Agile, Micro-Services &\\nMainframe Operations, Tools and Techniques- WebEnabler,\\nOperation Sentinel Console, MISER\\nPython Developer\\n66 Degrees Internation PVT. LTD.(Formally QWINIX\\nTECHNOLOGIES PVT. LTD), Mysuru\\nPLATFORM: Python,Fast-API,Flask, GCP, GIT, Docker,\\nMicro-Services.\\nThese technologies have been used for Cloud\\nNative and Product Modernization, which is\\nbeing designed to migrate the Legacy System\\nDatabase records to Google Cloud\\nPlatform(GCP) to solve the real time cloud\\nproblems for Large Industries.\\nPROJECT DESCRIPTIONS:\\nData Validation Tools(DVT) is an open-source\\nrepository provided by Google, which allows the\\nsmooth Migration of Legacy Databases across the', metadata={'source': '../bb.pdf', 'page': 0}),\n",
       " Document(page_content='problems for Large Industries.\\nPROJECT DESCRIPTIONS:\\nData Validation Tools(DVT) is an open-source\\nrepository provided by Google, which allows the\\nsmooth Migration of Legacy Databases across the\\nGoogle Cloud Platform Databases.\\nThis is micro-service has been developed to\\nreceived the various payload as Databases\\nconnection request which will be responsible for\\nmigrating legacy system DBs to Cloud DB.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\ncompanies to structuring there DB.\\nWorked on Fast-API, Flask, GCP, GitHub, Jira,\\nDocker, AlloyDB.\\n2023-03 -\\n2023-09\\nSenior Software Engineer\\nImpact Big Data Analytics Pvt. Ltd, Bangalore\\nPLATFORM: Python, Fast-API, PostgreSQL, GIT, Micro-\\n2022-04 -\\n2023-03\\nAddress\\nBangalore, Karnataka\\n560036\\nPhone\\n+91 8608121704\\nE-mail\\nKaoushikkumarr@gmail.co\\nm\\nhttps://www.linkedin.com\\n/in/kaoushik-kumar-\\n99426060/\\nPython\\nFast-API\\nFlask\\nDjango', metadata={'source': '../bb.pdf', 'page': 0}),\n",
       " Document(page_content='Competencies\\nServices.\\nThese technologies are used in most of AI Based\\nPlatform Application, which is being designed to\\nsolve real time e-commerce problems for Large\\nRetail Industries.\\nPROJECT DESCRIPTIONS:\\nMTP is one of the Micro-Service Based Platform\\nArchitect responsible for handling Multi-Tenant\\nApplication.\\nThis is one of Platform Service which is being built\\nfor handling all Multi-Tenant Based services\\naltogether.\\nPython is being used in backend to solve\\nchallenging problems of Large E-commerce\\ncompanies to increase their Revenues,\\nStructuring Ware-house products and many\\nmore.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nEmployD is one of the other Micro-Service Based\\napplication for Recruitment.\\nThis is another Platform Service which is being\\nbuilt for handling all Multi-Tenant Based services\\naltogether.\\nPython is being used in backend to solve\\nrecruitment problems of SMB or Small companies\\nto fulfill part-time or full-time employment for both\\nEmployee and Employers.', metadata={'source': '../bb.pdf', 'page': 1}),\n",
       " Document(page_content='altogether.\\nPython is being used in backend to solve\\nrecruitment problems of SMB or Small companies\\nto fulfill part-time or full-time employment for both\\nEmployee and Employers.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nPrice Smart is one of the another Micro-Service\\nBased application for E-commerce.\\nThis is one of application which is being designed\\nto optimism price of e-commerce products\\nbased on seasonal basis to enhance the sells for\\nmonths.\\nPython is being used in backend using Data\\nScience libraries.\\nWorked on Fast-API, PostgreSQL, BitBucket, Jira.\\nSoftware Development Engineer 1\\nEdGE Networks PVT. LTD.(C2H), Bangalore\\nPLATFORM: Python, Fast-API, Flask, PostgreSQL,\\nMongoDB, Elastic Search, GIT, Docker, RabbitMQ,\\n2020-07 -\\n2022-04\\nSQL\\nMySQL\\nGit\\nJIRA\\nMicrosoft Outlook\\nDocker\\nSQL Server\\nMongoDB\\nPostgreSQL\\nElastic Search\\nRabbit-MQ\\nPub-Sub\\nBig Query\\nAlloy DB\\nGCP\\nAgile\\nGitHub\\nOffice 365\\nHTTP\\nGoogle Docs\\nPostman\\nCloud Services\\nPython, Fast-API,\\nFlask, Django, PostgreSQL,', metadata={'source': '../bb.pdf', 'page': 1}),\n",
       " Document(page_content='SQL Server\\nMongoDB\\nPostgreSQL\\nElastic Search\\nRabbit-MQ\\nPub-Sub\\nBig Query\\nAlloy DB\\nGCP\\nAgile\\nGitHub\\nOffice 365\\nHTTP\\nGoogle Docs\\nPostman\\nCloud Services\\nPython, Fast-API,\\nFlask, Django, PostgreSQL,\\nMongoDB, ElasOc Search,\\nGIT, Docker, RabbitMQ\\nMicro-Services, HTML, CSS,\\nBootstrap, Java Script,\\njQuery, Core Java.\\nGoogle Cloud\\nPlatform(GCP)\\nOS: Linux-Mint, Ubuntu,\\nWindows (10, 8.1, 8, 7,\\nServer), MacOS.\\nVersion Control: GitHub, Bit\\nBucket, GitLab.\\nDevOps: Docker.\\nTicketing Tools: Jira, CMS', metadata={'source': '../bb.pdf', 'page': 1}),\n",
       " Document(page_content=\"Hobbies\\nMicro-Services.\\nThese technologies are used in most of our AI\\nBased Application, which is being designed to\\nsolve the real time recruitment problems for Large\\nEnterprises Industries.\\nPROJECT DESCRIPTIONS:\\nIntegrations is one of the Micro-Service Based\\nArchitect Application responsible to communicate\\nwith various Third Parties Application.\\nThis is Inbound and Outbound Micro-Service\\nApplication which is responsible to communicate\\nwith various Third Party's Application by using their\\nservices into our Platform Based Application as\\nwell as to Another Products.\\nThe idea behind this service is to not to allow any\\nThird Party's API directly to use Platform Base\\nApplication as vice-versa.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\nduring the time of their Recruitments.\\nWorked on Fast-API, Flask, PostgreSQL, RabbitMQ,\\nGitLab, Docker, Jira.\\nPathfinder is one of the Career Progression\\nApplication based on AI platform.\", metadata={'source': '../bb.pdf', 'page': 2}),\n",
       " Document(page_content='during the time of their Recruitments.\\nWorked on Fast-API, Flask, PostgreSQL, RabbitMQ,\\nGitLab, Docker, Jira.\\nPathfinder is one of the Career Progression\\nApplication based on AI platform.\\nThis is one of the Wrapper Based Application (also\\ncalled as BFF) which multi-Tenant (i.e: Clients)\\nbased product, can be communicated with\\nPlatform-Based-Application (i.e., TDP) to suggest\\nthe Next Career Progression Road Map to the\\nInternal Employees and helping them to choose\\nanother latest technology for their Career\\nGrowth.\\nPython is being used in backend by using Flask as\\nFramework to solve the challenges and problems\\nof Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nRecruit is one of the Recruitment Application based\\non AI platform\\nThis is another Wrapper Based Application (also\\ncalled as BFF) which multi-Tenant (i.e.; Clients)\\nbased product, can be communicated with\\nAgile\\nRESTFul\\nDatabase programming\\nProgramming\\nProduct development\\nTesting and maintenance', metadata={'source': '../bb.pdf', 'page': 2}),\n",
       " Document(page_content='called as BFF) which multi-Tenant (i.e.; Clients)\\nbased product, can be communicated with\\nAgile\\nRESTFul\\nDatabase programming\\nProgramming\\nProduct development\\nTesting and maintenance\\nAPI design knowledge\\nWeb-based software\\nengineering\\nBuild releases\\nCode reviews\\nReading News Paper,\\nWatching News, Yoga.', metadata={'source': '../bb.pdf', 'page': 2}),\n",
       " Document(page_content='Platform-Based-Application (i.e., TDP) to help to\\nresolve the various challenges at the One of\\nRecruitment of the New Joinee.\\nPython Script is used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nTDP is one of the latest and the Platform Based on AI\\nPlatform Service\\nThis is one of the latest Platform Based Service\\nwhich is being built as a product that can be\\nresponsible for handling all the Multi-Tenant\\nBased Wrapper (BFFs) products altogether.\\nAll the above products (i.e.; Integrations,\\nPathfinder, Recruit, etc..) have to be under the\\ncontrol of this TDP Platform.\\nPython Script is used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, PostgreSQL, GitLab, Docker,\\nJira.\\nCSE is one of the Older Version of Recruitment\\nApplication\\nThis is one of the Oldest Application of EdGE\\nNetwork, which has all the features of our Newest\\nApplication such as Integration as well as Recruit.', metadata={'source': '../bb.pdf', 'page': 3}),\n",
       " Document(page_content='Application\\nThis is one of the Oldest Application of EdGE\\nNetwork, which has all the features of our Newest\\nApplication such as Integration as well as Recruit.\\nThe main difference is from the newest one is, it\\nhas no AI well as Tenant Based features.\\nPython has been used in backend to solve the\\nchallenges and problems of Large Enterprises.\\nWorked on Flask, MongoDB, Elastic Search,\\nGitLab, Docker, Jira.\\nAssociate Product Engineer\\nTechtree IT Systems Pvt. Ltd, Bangalore\\nPLATFORM: Python, Django, MySQL, HTML, CSS,\\nBootstrap, Java Script, jQuery.\\nGIT, Pandas, Numpy, Excel.\\nThe Reciproci is a platform to create, store,\\nupdate, and \\uf001x the Ecommerce, Loyalty market\\ndeals.\\nThe Reciproci is Market Software developed on\\nnative windows platform.\\nWorked with Data Science team using latest tools\\n2020-02 -\\n2020-04', metadata={'source': '../bb.pdf', 'page': 3}),\n",
       " Document(page_content='and techniques in trend.\\nPROJECT DESCRIPTION:\\nClub Apparel is one of the applications for\\nEcommerce.\\nEnd-to-End Build and Release Engineering and\\nConfiguration Management processes.\\nPython Script is used for backend to generate a\\nSales Reports on daily basic.\\nWorked on GIT, Bit Bucket, Jira.\\nHouse of Beauty is one of the applications for\\nEcommerce.\\nEnd-to-End Build and Release Engineering and\\nConfiguration Management processes.\\nPython Script is used for backend to generate a\\nSales Reports on daily basic.\\nWorked on GIT, Bit Bucket, Jira.\\nSystem Engineer\\nFidelity Information Services India PVT. LTD.(C2H),\\nBangalore\\nPLATFORM: Python, Django, Web Enabler, Operation\\nSentinel Console, MISER BI, Bastion Server, HTML,\\nCSS, Bootstraps, JavaScript, jQuery, PostgresDB,\\nPandas, Numpy, CORE JAVA.\\nPROJECT DESCRIPTION:\\nFinancial Claim Application which is used directly\\nto track the remarks/comments and process the\\ncustomers claim accordingly by releasing the\\nfund to participate at instances.', metadata={'source': '../bb.pdf', 'page': 4}),\n",
       " Document(page_content=\"PROJECT DESCRIPTION:\\nFinancial Claim Application which is used directly\\nto track the remarks/comments and process the\\ncustomers claim accordingly by releasing the\\nfund to participate at instances.\\nStock Market Web Application platform to\\nengage multiple users to check market rate and\\nbring investors to invest on various company's\\nportfolios.\\nImage Processing Application which is used to\\ndetect the facial images to unlock the\\napplication.\\nWeb Application for Real Estate which brings the\\nplatform for Realtors who can create, store,\\nupdate, sell, purchase or advertise their Real\\nEstate properties\\nWeb Application to manage the User profile,\\nBlogs and Comment\\n2017-08 -\\n2020-02\", metadata={'source': '../bb.pdf', 'page': 4}),\n",
       " Document(page_content=\"Education\\nGUI Application through which Banking Dataset\\n& Transaction queries can be managed\\nWeb Navigation System to \\uf001nd the Bank's\\nLocation, Branch Locations, ATM Locations and\\ncan implements more locations such as Best\\nHotels, Restaurants and Tour Places of country\\nWeb Insurance Application to search the closest\\nCustomer Details and their Policy Information\\nWeb Application to \\uf001nd out the closest account\\ndetails and statements of Users\\nWeb Enabler is a tool of Unisys Mainframe use for\\nupdating, cancellations of the Bank\\nCurrent.Transactions, Transactions History while\\ncreating the .Ach File, also use for checking the\\nATM Transactions, issues and \\uf001x it\\nOperation Sentinel Console is one of another\\ntools of Unisys Mainframe which is used to\\nmonitor, control the alerts during the Transaction\\nperiods\\nMISER Business Intelligence is the monitoring\\napplication of FIS use to confirm the Bank\\nTransactions, ATM Transactions, Predecessors and\\nFollowers Transactions End to End.\", metadata={'source': '../bb.pdf', 'page': 5}),\n",
       " Document(page_content='periods\\nMISER Business Intelligence is the monitoring\\napplication of FIS use to confirm the Bank\\nTransactions, ATM Transactions, Predecessors and\\nFollowers Transactions End to End.\\nBACHELOR OF ENGINEERING: Computer\\nScience And Engineering\\nANNAMALAI UNIVERSITY - Chidambaram, Tamil\\nNadu\\nGPA: 6.88, Good academic background and\\nrecognitions. Participated in various team playing\\nactivities as Student Welfare Member, Volunteered\\nvarious events. Took part in various social activities\\nsuch as YRC Blood Donation Camp, NSS Services,\\nand General Election Volunteer. A proud\\nrepresentative for Hostels In-mates welfare for\\nconsecutive two years.\\n2012-08 -\\n2016-05\\nHSC: Intermediate of Science\\nLALOO MANDAL HIGH SCHOOL - Gaya, Bihar\\nGPA: 65%, Good Academic Knowledge.\\nParticipated in various Extra Curricular Activities. Part\\nof the School Cricket team.\\n2010-03 -\\n2012-03', metadata={'source': '../bb.pdf', 'page': 5}),\n",
       " Document(page_content='No Degree: All Subjects\\nSHIVAM PUBLIC SCHOOL - Patna, Bihar\\nPercentage: 68%.\\n2008-04 -\\n2009-02', metadata={'source': '../bb.pdf', 'page': 6})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_split = text_splitter.split_documents(pdf_doc)\n",
    "text_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2593299c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x27b997707d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Embedding and Vector Store\n",
    "from langchain_community.embeddings import OpenAIEmbeddings  # Ensure you have set the OPENAI_API_KEY in your environment\n",
    "from langchain_community.embeddings import OllamaEmbeddings  # Ensure you have Ollama installed and running\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings  # Ensure you have the HuggingFace model downloaded\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(text_split, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcf8875e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'problems for Large Industries.\\nPROJECT DESCRIPTIONS:\\nData Validation Tools(DVT) is an open-source\\nrepository provided by Google, which allows the\\nsmooth Migration of Legacy Databases across the\\nGoogle Cloud Platform Databases.\\nThis is micro-service has been developed to\\nreceived the various payload as Databases\\nconnection request which will be responsible for\\nmigrating legacy system DBs to Cloud DB.\\nPython is being used in backend to solve the\\nchallenging problems of the Large Enterprises\\ncompanies to structuring there DB.\\nWorked on Fast-API, Flask, GCP, GitHub, Jira,\\nDocker, AlloyDB.\\n2023-03 -\\n2023-09\\nSenior Software Engineer\\nImpact Big Data Analytics Pvt. Ltd, Bangalore\\nPLATFORM: Python, Fast-API, PostgreSQL, GIT, Micro-\\n2022-04 -\\n2023-03\\nAddress\\nBangalore, Karnataka\\n560036\\nPhone\\n+91 8608121704\\nE-mail\\nKaoushikkumarr@gmail.co\\nm\\nhttps://www.linkedin.com\\n/in/kaoushik-kumar-\\n99426060/\\nPython\\nFast-API\\nFlask\\nDjango'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"problems for Large Industries\"  # Replace with your query sentence or search term.\n",
    "retreival = db.similarity_search(query=query)\n",
    "retreival[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
